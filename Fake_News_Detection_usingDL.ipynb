{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCBcySeaTWGn",
        "outputId": "89b3d496-be02-4972-d74b-b21b962d756c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, SpatialDropout1D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true = pd.read_csv('/content/true.csv')\n",
        "fake = pd.read_csv('/content/fake.csv')\n",
        "\n",
        "true['Class'] = \"true\"\n",
        "fake['Class'] = \"fake\"\n",
        "\n",
        "data = pd.concat([true, fake], ignore_index=True)\n",
        "\n",
        "print(data.head())\n",
        "print(data.isnull().sum())\n",
        "\n",
        "df = data.dropna()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEbuksbmUPNn",
        "outputId": "84606f56-677d-4253-cd46-fa17eab8a384"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  \\\n",
            "0  As U.S. budget fight looms, Republicans flip t...   \n",
            "1  U.S. military to accept transgender recruits o...   \n",
            "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
            "3  FBI Russia probe helped by Australian diplomat...   \n",
            "4  Trump wants Postal Service to charge 'much mor...   \n",
            "\n",
            "                                                text       subject  \\\n",
            "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
            "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
            "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
            "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
            "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
            "\n",
            "                 date Class  \n",
            "0  December 31, 2017   true  \n",
            "1  December 29, 2017   true  \n",
            "2  December 31, 2017   true  \n",
            "3  December 30, 2017   true  \n",
            "4  December 29, 2017   true  \n",
            "title      0\n",
            "text       0\n",
            "subject    0\n",
            "date       0\n",
            "Class      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['processed_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "X = df['processed_text']\n",
        "y = df['Class']\n",
        "\n",
        "y = y.map({'true': 0, 'fake': 1})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw8qIa6FUdEL",
        "outputId": "874da748-3a81-473c-9ea0-4899d7182591"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_vec.toarray(), maxlen=100)\n",
        "X_test_pad = pad_sequences(X_test_vec.toarray(), maxlen=100)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=100))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_pad, y_train, epochs=3, batch_size=64, validation_data=(X_test_pad, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6Djzow_Uytp",
        "outputId": "1307512e-bf35-48d6-b19f-364b33ac29f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 211ms/step - accuracy: 0.5195 - loss: 0.6925 - val_accuracy: 0.5178 - val_loss: 0.6927\n",
            "Epoch 2/3\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 208ms/step - accuracy: 0.5213 - loss: 0.6925 - val_accuracy: 0.5178 - val_loss: 0.6926\n",
            "Epoch 3/3\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 209ms/step - accuracy: 0.5248 - loss: 0.6922 - val_accuracy: 0.5178 - val_loss: 0.6926\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d7749a970d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test_pad, y_test, verbose=1)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "y_pred = model.predict(X_test_pad)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBgxY93zU23X",
        "outputId": "4dacf309-a2bc-494d-d234-9ca1187d3e24"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5269 - loss: 0.6917\n",
            "Test Accuracy: 51.78%\n",
            "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step\n",
            "Confusion Matrix:\n",
            "[[   0 4330]\n",
            " [   0 4650]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_article = [\"Donald Trump just couldn t wish all Americans a Happy New Year and leave it at that. Instead, he had to give a shout out to his enemies, haters and the very dishonest fake news media. The former reality show star had just one job to do and he couldn t do it. As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media\"]\n",
        "sample_article_vec = vectorizer.transform(sample_article)\n",
        "sample_article_pad = pad_sequences(sample_article_vec.toarray(), maxlen=100)\n",
        "prediction = np.argmax(model.predict(sample_article_pad))\n",
        "print(f\"Prediction is \",prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2b37hIoU5GB",
        "outputId": "619dc6d0-2913-46a4-e9c2-1f906fa67e45"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "Prediction is  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7YUbs6dXc164"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}